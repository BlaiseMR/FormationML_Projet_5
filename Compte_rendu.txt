15/12/21

1) Récupération des données
	- Changer la requette de récupération des données

2) Traitement du texte
	- Supprimer les stop words
	- Enlever les carractères spéciaux
	- Faire un lemmatizer

3) Analyse du dataset
	- Etudier les tags les plus données

4) Réduction dimensionnel
	- Sélectionner les questions dans les 10-50 tags les plus utilisées

5) Mettre en place un git Hub

6) Mise en forme des datasets de modélisation
	- Merge le titre et le body

	a. TF-idf
	b. Word2vec
	c. Doc2vec

7) Modélisation
	Non-supervisés
		a. Lattente Dirichlet Allocation (LDA)
		-> Permet de définir le nombre de sujet
			- Mettre en place un GridSearch et évaluer le modèle la perplexcité ou la cohérence.

		-> Mettre en place une méthode supervisé ou non pour attribuer les tags

	Supervisés
	-> Permet de créer des modèles pour attribuer des tags
		b. OneVersusRest
		c. Chain

8) Méthode d'évaluation des données

23/12/21

1) Récupération des données
	- Changer la requette de récupération des données (important)
	- On veut 90 000 individues

2) Traitement du texte
	- Ok

3) Analyse du dataset
	Analys univarié
	- Mots les plus récurents dans le titre et body
	- Nombre de mots
		-> Sélectionner les titre et body dans la tendence moyenne de taille
	- Nombre de Tags
		-> Filtrer le nombre de tags par question
		-> Filtrer les question qui ont moins 1 tags dans les 10-50 meilleurs (500 au début) (done)
	- Regarder la fréquence des mots
		-> Filtre le bruit niveau contenu

	Analyse multivariée
	- Semble pas important

4) Réduction dimensionnel
	- Sélectionner les questions dans les 10-50 tags les plus utilisées

5) Mettre en place un git Hub

6) Mise en forme des datasets de modélisation
	- Merge le titre et le body

	a. TF-idF
	b. Word2vec
	c. Doc2vec
	d. Réseau de neuronens (Avancée)

7) Modélisation
	Non-supervisés
		a. Lattente Dirichlet Allocation (LDA)
		-> Permet de définir le nombre de sujet
			- Mettre en place un GridSearch et évaluer le modèle la perplexcité ou la cohérence.
			- TopicXDoc, TagsXDoc -> TagsXTopics
		-> Evaluer le modèle
			- Accuracy
			- f1_score
			- Précision
			- Recall
			
		b. NMF (sklearn)
		-> Mettre en place une méthode supervisé ou non pour attribuer les tags aux topics
			
	Supervisés
	-> Permet de créer des modèles pour attribuer des tags
		a. OneVersusRest
			- SVM, LogisticRegression, RandomForest, XGBoost
		b. Chain
			- SVM, RandomForest, XGBoost

	-> ROC curve et matrice de graham ?

8) Méthode d'évaluation des données
	- Précision
	- Rappel
	- f1 score
	- accuracy

9) Développer une api dans Flask Heroku

6/01/2022

1) Récupération des données
	- Ok

2) Traitement du texte
	- Ok

3) Analyse du dataset
	- Ok

5) Mettre en place un git Hub
	- Ok

6) Mise en forme des datasets de modélisation
	- BOW
		/!\ Attention choix no_above -> 50%

	a. TF-idF
	b. Word2vec
	c. Doc2vec
	d. Réseau de neuronens (Avancée)

7) Modélisation
	- Diviser le dataset en 3
		-> Training (70)
		-> Test (20)
		-> Eval (10)

	- Installer PyLDAvis 
	- Non-supervisés
		a. Lattente Dirichlet Allocation (LDA)
		-> Permet de définir le nombre de sujet
			- Evaluer la perplexcité ou la cohérence du modèle.
			
		b. NMF (sklearn)
		-> Mettre en place une méthode supervisé ou non pour attribuer les tags aux topics
	-> TopicXDoc, TagsXDoc -> TagsXTopics
		- Choisir les (2-3) plus grandes valeurs

	-> Evaluer le modèle
		- Accuracy
		- Précision
		- F1_score
		- Recall
		- Jaccard
			
	Supervisés
	-> Permet de créer des modèles pour attribuer des tags
		a. OneVersusRest
			- SVM, LogisticRegression, RandomForest, XGBoost
		b. Chain
			- SVM, RandomForest, XGBoost

	-> Evaluer le modèle
		- Accuracy
		- Précision
		- F1_score -> plus important
		- Recall
		- Jaccard -> plus important

8) Développer une api dans Flask Heroku


12/01/2022

6) Mise en forme des datasets de modélisation
	-> Tfidf avec skl au lieu de gensim

7) Modélisation
	-> Matrice de confusion pour évaluer le modèle
		- valeur prédite X valeurs réel

	-> Evaluer
		- Accuracy
		- Précision
		- F1_score
		- Recall
		- Jaccard

L'étiquetage peut-être compliqué à mettre en place.

8) Google collab, kaggle
	-> requiremet.txt :
		pip install -r requiremnt.txt (7heures max/session)

19/01/2022
7) Modélisation
	- Non-supervisé
		-> regarder la correspondance entre les tags et les mots du topics.
		-> problèmatique de comment associer les tags au topics
		-> Les résultats ne sont pas fou, mais il faut obtenir des résultats cohérent

	- Supervisé
		-> Vestorization(TFidF/word2vec/doc2vec), model(Linear/SVC/XGBoost/RandomForest), apprentissage (OVR/Chain)

24/01/2022
7) Modélisation
	- SVC est à passé
	- Logistic Regression, XGBoost, Random Forest
		-> PC fixe = word2vec, doc2vec
		-> Optimisation en changeant les taille des vecteurs, évaluation avec les scores des modèles.
	- Le reste est avec google collab

8) Développer une api dans Flask, hébergeur gratuit : Heroku
	- Compresser les données avec bz2 pour les Random Forest
 
9) Ecrire le rapport en attendant sur le traitement des données et les modèles non-supervisés.
(S'inspirer des différents tuto que l'on a trouvé)
	- Décrire les modèle de vectorisation
	- Décrire les métriques utilisés
	- Présenter les figure avec LDA et décrire
	- Ne pas présenter des bout de code

1/02/2022

9)
	Parler du temps de calcul comme un paramètre de sélection

8/02/2022
	-> Arrêt sur le Word2vec

	On veut qu'il donne un maximum de bon Tags, c'est pour ça que veux le meilleur Recall
	Le f1_score est le compromis entre la précision et le recall -> Bon compromis entre Recall et Précision
	Le Jaccard fait l'intersection entre ce qui est prédit et ce qui est réel

L'api est plus important que l'article
	https://towardsdatascience.com/how-to-deploy-your-custom-ml-model-with-streamlit-and-heroku-53456cb054fb
	https://www.analyticsvidhya.com/blog/2021/10/a-complete-guide-on-machine-learning-model-deployment-using-heroku/
